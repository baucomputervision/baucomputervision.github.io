---
layout: page
title: Research
subtitle: Final Year Projects (Undergraduate)
permalink: /research/fyp/
---
{% include nav-research.html  %}

## Final Year Projects for 2020/2021

The following are projects to be offered for undergraduate FYPs for the upcoming academic session. Do inform us directly if you have enquiries or are interested to take it up. Students working on these projects will be affiliated with our lab and will have access to our facilities (**hot-desks** are provided at the lab, but subject to availability). 
  
**Dr. Wong Lai Kuan**
- Joint Prediction of Technical and Aesthetics Image Quality
- Content-driven Image Enhancement SDK with An Application Interface
- Context-Aware Image Emotion Prediction
- DECOVID-CXR-II: A multimodal AI model for severity assessment of COVID-19 Infection using Chest X-Rays
- DECOVID-CT-II: A multimodal deep learning model for severity assessment of COVID-19 Infection using CT Scan
- PhotoViewRec: A Machine Learning Model for Recommending Photographic View with Good Composition

**Dr. Loh Yuen Peng**
- Leaf Images Synthesis- 
- Plant Disease Classification
- Object Recognition in Low-light Images
- Dashboard Camera View Vehicle License Plate Recognition and Compliance Verification

**Dr. Pee Chih Yang**
- Moment based Handwritten Signature Verification System
- Moment based Leaf classification System
- Plant Disease Assessment using Deep Learning

**Mr. Albert Quek**
- Virtual Reality Application Treatment for Trypanophobia
- Physical Rehabilitation using Virtual Reality
- Locomotion Gameplay for Virtual Reality Game
- Immersive Virtual Reality Game that Utilizes Wind Mechanics
- Escape Room Horror Game
- RPG Exergame in Virtual Reality
- Audio Based Controller for Game

{::comment}
{% include imagethumbnailblock.html align="left" url="/images/aquas.png" width="120px" height="120px" padding="right" %}
Most state-of-the-art techniques for HAR have been designed to perform well under constrained and highly controlled conditions. However, these capabilities may not be easily replicable in real-world surveillance conditions (via devices such as CCTV or web cameras) where video quality may be naturally poor. We investigate new representations for recognizing human activities in adverse quality surveillance videos.
{: #proj-description}
{% include clearfloat.html prevfloat="left" %}

[Download Link](https://drive.google.com/file/d/0B_3N19NSFoBgOFVPdzg5R21hUHM)
{:/comment}
