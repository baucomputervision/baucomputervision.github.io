---
layout: page
title: Research
permalink: /research/
---
{% include nav-research.html  %}

## Projects

We have a number of funded and non-funded projects which are currently on-going.

### Large-scale Aesthetic Evaluation of Photographs (LAttE)
{% include imagethumbnailblock.html align="left" url="/images/latte.jpg" width="120px" height="120px" padding="right" %}
Image aesthetic evaluation is a research field which aims to design computationally-driven methods which can automatically rate or predict the perceived aesthetic quality of an image or photograph by learning from image content, photographic rules and other semantic information. We investigate how features can be learned in an unsupervised manner as opposed to traditional hand-crafted rules, and design new deep learning architectures to evaluate the aesthetic beauty of photographs.
{: #proj-description}
Magzhan Kairanbay, Hii Yong Lian, John See, Wong Lai Kuan
{: #proj-members}
{% include clearfloat.html prevfloat="left" %}

### Facial Micro-Expression Analysis
{% include imagethumbnailblock.html align="left" url="/images/microexp-emm.gif" height="140px" padding="right" %}
A micro-expression is a brief and involuntary facial movement which reveals a genuine emotion that a person tries to hide. Psychologists have been studying facial micro-expressions since the 1960â€™s, computer scientists are now beginning to explore the possibility of spotting and identifying these micro-expressions using machine vision and learning algorithms; we aim to discover novel methods for doing so. This contemporary field of research has potential applications for clinical diagnosis of psychological conditions (autism and depression), criminal interrogation and lie detection. This project is in collaboration with institutions in UK and China.
{: #proj-description}
Huai-Qian Khor, John See
{: #proj-members}
{% include clearfloat.html prevfloat="left" %}

### Computational 3D Model of Forearm Rotation
{% include imagethumbnailblock.html align="left" url="/images/3dforearm.png" height="120px" padding="right" %}
The mechanism that allows for human forearm rotation is still poorly understood. As a result, sub-optimal surgical treatment of fractured radius or ulna can lead to impaired forearm motion. We aim to develop a physically accurate 3D dynamic model of human forearm rotation from CT scan, with visualization of the model, the dynamic rotation and tensing of interosseous membrane. This is a project in collaboration with National University of Singapore (NUS) and Singapore General Hospital (SGH).
{: #proj-description}
Muhammad Faiz, Wong Lai Kuan, John See, Loh Yuen Peng
{: #proj-members}
{% include clearfloat.html prevfloat="left" %}

---

## Past Projects
<small>Here's some of our previous completed projects, which are still very much relevant today.</small>

### Action Recognition in Adverse Quality Surveillance (AQuaS)
{% include imagethumbnailblock.html align="left" url="/images/aquas.png" width="120px" height="120px" padding="right" %}
Most state-of-the-art techniques for HAR have been designed to perform well under constrained and highly controlled conditions. However, these capabilities may not be easily replicable in real-world surveillance conditions (via devices such as CCTV or web cameras) where video quality may be naturally poor. We investigate new representations for recognizing human activities in adverse quality surveillance videos.
{: #proj-description}
{% include clearfloat.html prevfloat="left" %}

### Aesthetics-driven Stereo Retargeting and Recomposition
{% include imagethumbnailblock.html url="/images/retarget.jpg" width="480px" padding="right" %}
With the recent availability of stereoscopic displays such as 3D monitor, 3D television and stereo camera phone, there is an increasing need for stereo image retargeting and recomposition techniques. Image retargeting aims to resize an image to fit different aspect ratios and sizes while image recomposition attempts to computationally modify the composition of an image to mimic a professional photo. We investigate new aesthetic-driven methods for retargeting and recomposition for stereo image pairs.
{: #proj-description}
{% include clearfloat.html prevfloat="left" %}

### Long-term Video Surveillance (LoViS)
{% include imagethumbnailblock.html align="left" url="/images/lovis.png" width="120px" height="120px" padding="right" %}
In a long-term period, video surveillance takes on a different perspective. Habitual behaviors of people or permanent changes to objects can be observed while anomalous "out-of-norm" variations can also be traced. We investigate how these variational patterns can be extracted over a long period of time to gain a high-level understanding of various factors at play.
{: #proj-description}
{% include clearfloat.html prevfloat="left" %}



## Funding/Grants

### External (Industry-funded)
- **Formulation of high discriminative discrete Krawtchouk moment invariants with Deep Neural Network learning model for plant condition assessment**{:.hilite}, 2021-**Ongoing**{:.marker}, MMU-Poladrone Collaboration, PI: Pee Chih Yang
- **New Framework for Modeling Concurrent Low-light Image Enhancement and Object Classification with Deep Neural Networks**{:.hilite}, 2021-**Ongoing**{:.marker}, MMU-NCTU, Taiwan, PI: Loh Yuen Peng
- **Research, Development and Validation of Visual Cloud Systems Analytics Framework for Internet-of-Things Applications**{:.hilite}, 2020-**Ongoing**{:.marker}, CREST R&D Grant, PI: John See
- **AI Technologies for Visual and Textual Media**{:.hilite}, 2020-**Ongoing**{:.marker}, MMU-Astro Collaboration, PI: John See
- **Automatic Enhancement of Photographs for Improved Aesthetics Quality**{:.hilite}, 2020-**Ongoing**{:.marker}, MMU-123RF Collaboration, PI: Wong Lai Kuan
- **SHERLOCK: Video Analytics for Multi-Camera Long-term Surveillance in Smart Cities**{:.hilite}, 2016-2018, TM R&D Fund, PI: John See

### External (Government/Institutional-funded)
- **Player-Dependent Predictive Modeling for Automated Tactical Analysis of Badminton Videos**{:.hilite}, 2019-**Ongoing**{:.marker}, MOHE FRGS Grant, PI: Ban Kar Weng
- **Aesthetics-driven, Crop-and-Warp Image Recomposition Using Dual Learning Framework**{:.hilite}, 2019-**Ongoing**{:.marker}, MOHE FRGS Grant, PI: Wong Lai Kuan
- **Multi-scale Object Behaviour Recognition in Complex Videos**{:.hilite}, **2017-2019, One Belt One Road Initiative Young Scholar Exchange Grant, Co-PI: John See
- **Novel Methods for Spotting and Recognition of Spontaneous Facial Micro-Expressions from Naturalistic Situations**{:.hilite}, 2016-2019, MOHE FRGS Grant, PI: John See
- **Visual Recognition of Human Activities using Spatio-temporal Information for Low Quality Surveillance Video**{:.hilite}, 2014-2016, MOHE FRGS Grant, PI: John See
- **Aesthetics-driven Stereoscopic Image Enhancement Algorithms for Better 3D Experience**{:.hilite}, 2013-2015, MOHE FRGS Grant

### Internal
- **Low-light Image Enhancement and Recognition**{.hilite}, 2019-2020, Mini Fund, PI: Loh Yuen Peng
- **Immersive Data Visualization using Virtual Reality**{:.hilite}, 2019-2020, Mini Fund, PI: Albert Quek
- **Semi-supervised, Aesthetics-driven Image Recomposition Using Generative Adversarial Model**{:.hilite},
2018-2019, Mini Fund, PI: Wong Lai Kuan
- **Large-scale Computational Aesthetic Evaluation of Photographs using Deep Learning**{:.hilite}, 2016-2019, MMU-GRA Funding, PI: John See
- **In Silico Modelling of Interosseous Membrane Behaviour in 3D Forearm Rotation**{:.hilite}, 2016-2018, MMU-GRA Funding, PI: Wong Lai Kuan
- **Efficient Streaming of Real-time 360-degree Videos for Head Mounted Displays**{:.hilite}, 2017-2018, MMU R&D Capex Fund / MMU-GRA Funding, PI: Albert Quek
- **Virtual Reality Fire Safety Intervention Program**{:.hilite}, 2015-2017, Mini Fund, Albert Quek
